{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ac97e58d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-16T14:00:38.597027Z",
     "iopub.status.busy": "2024-04-16T14:00:38.596497Z"
    },
    "papermill": {
     "duration": 0.002278,
     "end_time": "2024-04-16T15:37:42.820930",
     "exception": false,
     "start_time": "2024-04-16T15:37:42.818652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, confusion_matrix, \\\n",
    "    precision_recall_fscore_support, roc_auc_score\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.layers import Dense, Conv1D, Flatten, Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "epochs_number = 150  # number of epochs for the neural networks\n",
    "test_set_size = 0.2  # percentage of the test size comparing to the whole dataset\n",
    "oversampling_flag = 0  # set to 1 to over-sample the minority class\n",
    "oversampling_percentage = 0.2  # percentage of the minority class after the oversampling comparing to majority class\n",
    "\n",
    "\n",
    "# Definition of functions\n",
    "def read_data():\n",
    "    rawData = pd.read_csv('/kaggle/input/electricity-theft-detection/preprocessedR95.csv')\n",
    "\n",
    "    # Setting the target and dropping the unnecessary columns\n",
    "    y = rawData[['FLAG']]\n",
    "    X = rawData.drop(['FLAG', 'CONS_NO'], axis=1)\n",
    "\n",
    "    print('Normal Consumers:                    ', y[y['FLAG'] == 0].count()[0])\n",
    "    print('Consumers with Fraud:                ', y[y['FLAG'] == 1].count()[0])\n",
    "    print('Total Consumers:                     ', y.shape[0])\n",
    "    print(\"Classification assuming no fraud:     %.2f\" % (y[y['FLAG'] == 0].count()[0] / y.shape[0] * 100), \"%\")\n",
    "\n",
    "    # columns reindexing according to dates\n",
    "    X.columns = pd.to_datetime(X.columns)\n",
    "    X = X.reindex(X.columns, axis=1)\n",
    "\n",
    "    # Splitting the dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y['FLAG'], test_size=test_set_size, random_state=0)\n",
    "    print(\"Test set assuming no fraud:           %.2f\" % (y_test[y_test == 0].count() / y_test.shape[0] * 100), \"%\\n\")\n",
    "\n",
    "    # Oversampling of minority class to encounter the imbalanced learning\n",
    "    if oversampling_flag == 1:\n",
    "        over = SMOTE(sampling_strategy=oversampling_percentage, random_state=0)\n",
    "        X_train, y_train = over.fit_resample(X_train, y_train)\n",
    "        print(\"Oversampling statistics in training set: \")\n",
    "        print('Normal Consumers:                    ', y_train[y_train == 0].count())\n",
    "        print('Consumers with Fraud:                ', y_train[y_train == 1].count())\n",
    "        print(\"Total Consumers                      \", X_train.shape[0])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def results(y_test, prediction):\n",
    "    print(\"Accuracy\", 100 * accuracy_score(y_test, prediction))\n",
    "    print(\"RMSE:\", mean_squared_error(y_test, prediction, squared=False))\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, prediction))\n",
    "    print(\"F1:\", 100 * precision_recall_fscore_support(y_test, prediction)[2])\n",
    "    print(\"AUC:\", 100 * roc_auc_score(y_test, prediction))\n",
    "    print(\"Confusion matrix: \\n\",confusion_matrix(y_test, prediction), \"\\n\")\n",
    "\n",
    "\n",
    "def CNN2D(X_train, X_test, y_train, y_test):\n",
    "    print('2D - Convolutional Neural Network:')\n",
    "\n",
    "    # Transforming every row of the train set into a 2D array and then into a tensor\n",
    "    n_array_X_train = X_train.to_numpy()\n",
    "    n_array_X_train_extended = np.hstack((n_array_X_train, np.zeros(\n",
    "        (n_array_X_train.shape[0], 2))))  # adding two empty columns in order to make the number of columns\n",
    "    # an exact multiple of 7\n",
    "    week = []\n",
    "    for i in range(n_array_X_train_extended.shape[0]):\n",
    "        a = np.reshape(n_array_X_train_extended[i], (-1, 7, 1))\n",
    "        week.append(a)\n",
    "    X_train_reshaped = np.array(week)\n",
    "\n",
    "    # Transforming every row of the train set into a 2D array and then into a tensor\n",
    "    n_array_X_test = X_test.to_numpy()  # X_test to 2D - array\n",
    "    n_array_X_train_extended = np.hstack((n_array_X_test, np.zeros((n_array_X_test.shape[0], 2))))\n",
    "    week2 = []\n",
    "    for i in range(n_array_X_train_extended.shape[0]):\n",
    "        b = np.reshape(n_array_X_train_extended[i], (-1, 7, 1))\n",
    "        week2.append(b)\n",
    "    X_test_reshaped = np.array(week2)\n",
    "\n",
    "    input_shape = (1, 148, 7, 1)  # input shape of the tensor\n",
    "\n",
    "    # Model creation\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(kernel_size=(7, 3), filters=32, input_shape=input_shape[1:], activation='relu',\n",
    "                     data_format='channels_last'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    # model.summary()\n",
    "    #     model.fit(X_train_reshaped, y_train, validation_split=0.1, epochs=i, shuffle=False, verbose=0)\n",
    "    model.fit(X_train_reshaped, y_train, validation_split=0.1, epochs=epochs_number, shuffle=False, verbose=1)\n",
    "\n",
    "    # prediction = model.predict_classes(X_test)\n",
    "    #prediction = model.predict_classes(X_test_reshaped)\n",
    "    predictions_proba = model.predict(X_test_reshaped)\n",
    "    predictions = (predictions_proba > 0.5).astype(int)  # Apply threshold of 0.5\n",
    "    model.summary()\n",
    "    results(y_test, predictions)\n",
    "\n",
    "# ----Main----\n",
    "X_train, X_test, y_train, y_test = read_data()\n",
    "CNN2D(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f02e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T15:37:42.826861Z",
     "iopub.status.busy": "2024-04-16T15:37:42.826433Z",
     "iopub.status.idle": "2024-04-16T15:37:44.943537Z",
     "shell.execute_reply": "2024-04-16T15:37:44.942370Z"
    },
    "papermill": {
     "duration": 2.122832,
     "end_time": "2024-04-16T15:37:44.945744",
     "exception": false,
     "start_time": "2024-04-16T15:37:42.822912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/electricity-theft-detection/visualization.csv\n",
      "/kaggle/input/electricity-theft-detection/Validation_SansFLAG.csv\n",
      "/kaggle/input/electricity-theft-detection/Validation.csv\n",
      "/kaggle/input/electricity-theft-detection/preprocessedR95.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt   # data visualization\n",
    "import seaborn as sns             # statistical data visualization\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4808241,
     "sourceId": 8134280,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.296046,
   "end_time": "2024-04-16T15:37:45.467106",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-16T15:37:40.171060",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
