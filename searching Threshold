{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 100 CLIENTS SEUIL :: 90e percentile","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport itertools\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom math import sqrt\nimport numpy as np\n\n# Charger et préparer les données\ndata = pd.read_csv(r\"S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\preprocessedR90_FRAUDE_100_Client.csv\", header=0, parse_dates=[0], index_col=0, squeeze=True)\ndf_transposed = data.set_index('CONS_NO').T\ndf_transposed.index = pd.to_datetime(df_transposed.index)\n\n# Définir le seuil de pic\nseuil_pic = 0.622\n\n# Grid search configurations\np_range = range(0, 5)\nd_range = range(0, 5)\nq_range = range(0, 5)\npdq = list(itertools.product(p_range, d_range, q_range))\n\nresults = []\n\n# Analyse pour chaque client\nfor cons_no, selected_data in df_transposed.iteritems():\n    try:\n        # Grid search pour ARIMA\n        best_aic = float(\"inf\")\n        best_pdq = None\n        for params in pdq:\n            try:\n                model = ARIMA(selected_data.dropna(), order=params)\n                result = model.fit()\n                if result.aic < best_aic:\n                    best_aic = result.aic\n                    best_pdq = params\n            except:\n                continue\n\n        # Création et ajustement du modèle ARIMA\n        model = ARIMA(selected_data.dropna(), order=best_pdq)\n        model_fit = model.fit()\n\n        # Faire des prédictions\n        predictions = model_fit.predict(start=0, end=len(selected_data) - 1)\n\n        # Identifier les pics\n        real_pics = selected_data[selected_data > seuil_pic]\n        pred_pics = predictions[selected_data > seuil_pic]\n\n        # Calculer les différences\n        differences = pred_pics - real_pics\n        max_diff = differences.max()\n        min_diff = differences.min()\n        mean_diff = differences.mean()  # Calcul de la moyenne des différences\n\n        # Stocker les résultats\n        results.append({\n            'CONS_NO': cons_no,\n            'Max_Difference': max_diff,\n            'Min_Difference': min_diff,\n            'Mean_Difference': mean_diff,  # Ajout de la moyenne des différences\n            'Number_of_Peaks': len(real_pics),\n            'Estimated_Peak_Values': pred_pics.mean()  # Moyenne des valeurs estimées des pics\n        })\n    except Exception as e:\n        print(f\"Error processing {cons_no}: {e}\")\n\n# Convertir les résultats en DataFrame\nresults_df = pd.DataFrame(results)\n\n# Chemin du fichier où vous souhaitez enregistrer les résultats\noutput_file_path = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Results_FRAUDE_100_Analysis.csv'\n\n# Enregistrer le DataFrame dans un fichier CSV\nresults_df.to_csv(output_file_path, index=False)\n\nprint(\"Results saved to CSV file.\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 100 CLIENTS SEUIL :: Validation Croisée","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport itertools\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom math import sqrt\nimport numpy as np\n\n# Charger et préparer les données\ndata = pd.read_csv(r\"S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\preprocessedR90_FRAUDE_100_Client.csv\", header=0, parse_dates=[0], index_col=0, squeeze=True)\ndf_transposed = data.set_index('CONS_NO').T\ndf_transposed.index = pd.to_datetime(df_transposed.index)\n\n# Définir le seuil de pic\nseuil_pic = 0.8\n\n# Grid search configurations\np_range = range(0, 5)\nd_range = range(0, 5)\nq_range = range(0, 5)\npdq = list(itertools.product(p_range, d_range, q_range))\n\nresults = []\n\n# Analyse pour chaque client\nfor cons_no, selected_data in df_transposed.iteritems():\n    try:\n        # Grid search pour ARIMA\n        best_aic = float(\"inf\")\n        best_pdq = None\n        for params in pdq:\n            try:\n                model = ARIMA(selected_data.dropna(), order=params)\n                result = model.fit()\n                if result.aic < best_aic:\n                    best_aic = result.aic\n                    best_pdq = params\n            except:\n                continue\n\n        # Création et ajustement du modèle ARIMA\n        model = ARIMA(selected_data.dropna(), order=best_pdq)\n        model_fit = model.fit()\n\n        # Faire des prédictions\n        predictions = model_fit.predict(start=0, end=len(selected_data) - 1)\n\n        # Identifier les pics\n        real_pics = selected_data[selected_data > seuil_pic]\n        pred_pics = predictions[selected_data > seuil_pic]\n\n        # Calculer les différences\n        differences = pred_pics - real_pics\n        max_diff = differences.max()\n        min_diff = differences.min()\n        mean_diff = differences.mean()  # Calcul de la moyenne des différences\n\n        # Stocker les résultats\n        results.append({\n            'CONS_NO': cons_no,\n            'Max_Difference': max_diff,\n            'Min_Difference': min_diff,\n            'Mean_Difference': mean_diff,  # Ajout de la moyenne des différences\n            'Number_of_Peaks': len(real_pics),\n            'Estimated_Peak_Values': pred_pics.mean()  # Moyenne des valeurs estimées des pics\n        })\n    except Exception as e:\n        print(f\"Error processing {cons_no}: {e}\")\n\n# Convertir les résultats en DataFrame\nresults_df = pd.DataFrame(results)\n\n# Chemin du fichier où vous souhaitez enregistrer les résultats\noutput_file_path = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Results_FRAUDE_SAUIL_ValidationCroise_100_Analysis.csv'\n\n# Enregistrer le DataFrame dans un fichier CSV\nresults_df.to_csv(output_file_path, index=False)\n\nprint(\"Results saved to CSV file.\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 100 CLIENTS SEUIL :: Modèle de Mélange Gaussien","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport itertools\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom math import sqrt\nimport numpy as np\n\n# Charger et préparer les données\ndata = pd.read_csv(r\"S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\preprocessedR90_FRAUDE_100_Client.csv\", header=0, parse_dates=[0], index_col=0, squeeze=True)\ndf_transposed = data.set_index('CONS_NO').T\ndf_transposed.index = pd.to_datetime(df_transposed.index)\n\n# Définir le seuil de pic\nseuil_pic = 0.34700620142162725\n\n# Grid search configurations\np_range = range(0, 5)\nd_range = range(0, 5)\nq_range = range(0, 5)\npdq = list(itertools.product(p_range, d_range, q_range))\n\nresults = []\n\n# Analyse pour chaque client\nfor cons_no, selected_data in df_transposed.iteritems():\n    try:\n        # Grid search pour ARIMA\n        best_aic = float(\"inf\")\n        best_pdq = None\n        for params in pdq:\n            try:\n                model = ARIMA(selected_data.dropna(), order=params)\n                result = model.fit()\n                if result.aic < best_aic:\n                    best_aic = result.aic\n                    best_pdq = params\n            except:\n                continue\n\n        # Création et ajustement du modèle ARIMA\n        model = ARIMA(selected_data.dropna(), order=best_pdq)\n        model_fit = model.fit()\n\n        # Faire des prédictions\n        predictions = model_fit.predict(start=0, end=len(selected_data) - 1)\n\n        # Identifier les pics\n        real_pics = selected_data[selected_data > seuil_pic]\n        pred_pics = predictions[selected_data > seuil_pic]\n\n        # Calculer les différences\n        differences = pred_pics - real_pics\n        max_diff = differences.max()\n        min_diff = differences.min()\n        mean_diff = differences.mean()  # Calcul de la moyenne des différences\n\n        # Stocker les résultats\n        results.append({\n            'CONS_NO': cons_no,\n            'Max_Difference': max_diff,\n            'Min_Difference': min_diff,\n            'Mean_Difference': mean_diff,  # Ajout de la moyenne des différences\n            'Number_of_Peaks': len(real_pics),\n            'Estimated_Peak_Values': pred_pics.mean()  # Moyenne des valeurs estimées des pics\n        })\n    except Exception as e:\n        print(f\"Error processing {cons_no}: {e}\")\n\n# Convertir les résultats en DataFrame\nresults_df = pd.DataFrame(results)\n\n# Chemin du fichier où vous souhaitez enregistrer les résultats\noutput_file_path = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Results_FRAUDE_SAUIL_Gaussien_100_Analysis.csv'\n\n# Enregistrer le DataFrame dans un fichier CSV\nresults_df.to_csv(output_file_path, index=False)\n\nprint(\"Results saved to CSV file.\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 100 CLIENTS SEUIL :: la Moyenne + Écart Type","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport itertools\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom math import sqrt\nimport numpy as np\n\n# Charger et préparer les données\ndata = pd.read_csv(r\"S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\preprocessedR90_FRAUDE_100_Client.csv\", header=0, parse_dates=[0], index_col=0, squeeze=True)\ndf_transposed = data.set_index('CONS_NO').T\ndf_transposed.index = pd.to_datetime(df_transposed.index)\n\n# Définir le seuil de pic\nseuil_pic = 0.7932744727771972\n\n# Grid search configurations\np_range = range(0, 5)\nd_range = range(0, 5)\nq_range = range(0, 5)\npdq = list(itertools.product(p_range, d_range, q_range))\n\nresults = []\n\n# Analyse pour chaque client\nfor cons_no, selected_data in df_transposed.iteritems():\n    try:\n        # Grid search pour ARIMA\n        best_aic = float(\"inf\")\n        best_pdq = None\n        for params in pdq:\n            try:\n                model = ARIMA(selected_data.dropna(), order=params)\n                result = model.fit()\n                if result.aic < best_aic:\n                    best_aic = result.aic\n                    best_pdq = params\n            except:\n                continue\n\n        # Création et ajustement du modèle ARIMA\n        model = ARIMA(selected_data.dropna(), order=best_pdq)\n        model_fit = model.fit()\n\n        # Faire des prédictions\n        predictions = model_fit.predict(start=0, end=len(selected_data) - 1)\n\n        # Identifier les pics\n        real_pics = selected_data[selected_data > seuil_pic]\n        pred_pics = predictions[selected_data > seuil_pic]\n\n        # Calculer les différences\n        differences = pred_pics - real_pics\n        max_diff = differences.max()\n        min_diff = differences.min()\n        mean_diff = differences.mean()  # Calcul de la moyenne des différences\n\n        # Stocker les résultats\n        results.append({\n            'CONS_NO': cons_no,\n            'Max_Difference': max_diff,\n            'Min_Difference': min_diff,\n            'Mean_Difference': mean_diff,  # Ajout de la moyenne des différences\n            'Number_of_Peaks': len(real_pics),\n            'Estimated_Peak_Values': pred_pics.mean()  # Moyenne des valeurs estimées des pics\n        })\n    except Exception as e:\n        print(f\"Error processing {cons_no}: {e}\")\n\n# Convertir les résultats en DataFrame\nresults_df = pd.DataFrame(results)\n\n# Chemin du fichier où vous souhaitez enregistrer les résultats\noutput_file_path = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Results_FRAUDE_SAUIL_EcartMean_100_Analysis.csv'\n\n# Enregistrer le DataFrame dans un fichier CSV\nresults_df.to_csv(output_file_path, index=False)\n\nprint(\"Results saved to CSV file.\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"- Calcul du moyenne des Nombres de Pics\n- Détermination de l'Intervalle avec Min de Min_Difference et Max de Max_Difference","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Charger les données depuis le fichier CSV\nfile_path = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Results_FRAUDE_SAUIL_ValidationCroise_100_Analysis.csv'\n#file_path = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Results_FRAUDE_SAUIL_EcartMean_100_Analysis.csv'\n#file_path = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Results_FRAUDE_100_Analysis.csv'\n#file_path = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Results_FRAUDE_SAUIL_Gaussien_100_Analysis.csv'\nresults_df = pd.read_csv(file_path)\n\n# Calcul du minimum des nombres de pics\nmin_number_of_peaks = results_df['Number_of_Peaks'].min()\n\n# Calcul du maximum des nombres de pics\nmax_number_of_peaks = results_df['Number_of_Peaks'].max()\n\n# Calcul du maximum des nombres de pics\nmean_number_of_peaks = results_df['Number_of_Peaks'].mean()\n\n# Calcul de l'intervalle pour Min_Difference et Max_Difference\ninterval_min_diff = results_df['Min_Difference'].min()\ninterval_max_diff = results_df['Max_Difference'].max()\n\n# Calcul de moyenne des moyennes \nmean_diff = abs(results_df['Mean_Difference']).mean()\n\n# Afficher les résultats calculés\nprint(f\"Minimum Number of Peaks: {min_number_of_peaks}\")\nprint(f\"Maximum Number of Peaks: {max_number_of_peaks}\")\nprint(f\"Mean Number of Peaks: {mean_number_of_peaks}\")\nprint(f\"Interval for Differences: [{interval_min_diff}, {interval_max_diff}]\")\n\nprint(f\"Mean Mean diff: {mean_diff}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TEST DE VALISATION ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Chemin vers les fichiers de données\nfile_path = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Results_FRAUDE_SAUIL_ValidationCroise_100_Analysis.csv'\n\n# Charger le fichier\nresults_df = pd.read_csv(file_path)\n\n# Seuil pour déterminer un pic de consommation\nthreshold = 0.8\n\n# Charger les données non étiquetées\ndf_sans_flag = pd.read_csv(r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Validation_SansFLAG.csv')\n\n# Fonction pour calculer le nombre de pics de consommation\ndef calculate_peaks(row, threshold):\n    return (row.iloc[2:] > threshold).sum()\n\n# Fonction pour calculer la moyenne de consommation\ndef calculate_mean(row):\n    return (row.iloc[2:]).mean()\n\n# Appliquer la fonction sur chaque ligne pour calculer le nombre de pics\ndf_sans_flag['Number_of_Peaks'] = df_sans_flag.apply(calculate_peaks, threshold=threshold, axis=1)\n\n# Appliquer la fonction sur chaque ligne pour calculer la moyenne de consommation\ndf_sans_flag['Mean_Of_Consommation'] = df_sans_flag.apply(calculate_mean, axis=1)\n\n# Calcul du maximum des nombres de pics\nmean_number_of_peaks = results_df['Number_of_Peaks'].mean()\n\n# Calcul de moyenne des moyennes \nmean_diff = abs(results_df['Mean_Difference']).mean()\n\n# Filtrer les clients avec une moyenne de consommation supérieure à mean_diff\ndf_filtered = df_sans_flag[df_sans_flag['Mean_Of_Consommation'] > mean_diff]\n\n# Étiqueter les données basées sur le nombre de pics et la moyenne de consommation\ndf_filtered['FLAG'] = df_filtered[['Number_of_Peaks', 'Mean_Of_Consommation']].apply(\n    lambda row: 1 if row['Number_of_Peaks'] > mean_number_of_peaks else 0, axis=1)\n\n# Sauvegarder le fichier avec les nouvelles étiquettes\noutput_path = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Validation_Etiquetee_CrossValidation.csv'\ndf_filtered.to_csv(output_path, index=False)\n\nprint(\"Données étiquetées et sauvegardées dans le fichier Validation_Etiquetee.csv.\")\nprint(df_filtered[['CONS_NO', 'Number_of_Peaks', 'FLAG', 'Mean_Of_Consommation']].head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\n\n# Chemin vers les fichiers de données étiquetées et les données brutes\noutput_path = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Validation_Etiquetee_CrossValidation.csv'\npath_validation = r'S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\Validation10.csv'\n\n# Charger le fichier étiqueté\ndf_etiquetee = pd.read_csv(output_path)\n\n# Charger le fichier de données brutes\ndf_validation = pd.read_csv(path_validation)\n\n# Vérifier la présence de la colonne 'FLAG' dans les deux DataFrames\nif 'FLAG' not in df_validation.columns:\n    raise ValueError(\"La colonne 'FLAG' est manquante dans le fichier de données brutes.\")\nif 'FLAG' not in df_etiquetee.columns:\n    raise ValueError(\"La colonne 'FLAG' est manquante dans le fichier de données étiquetées.\")\n\n# S'assurer que les deux DataFrames sont triés de la même manière\ndf_etiquetee = df_etiquetee.sort_values(by='CONS_NO').reset_index(drop=True)\ndf_validation = df_validation.sort_values(by='CONS_NO').reset_index(drop=True)\n\n# Vérifier les 'CONS_NO' présents dans les deux DataFrames\ncons_no_common = df_etiquetee['CONS_NO'].isin(df_validation['CONS_NO'])\n\n# Filtrer les DataFrames pour ne garder que les 'CONS_NO' communs\ndf_etiquetee = df_etiquetee[cons_no_common]\ndf_validation = df_validation[df_validation['CONS_NO'].isin(df_etiquetee['CONS_NO'])]\n\n# S'assurer que les deux DataFrames sont alignés\ndf_etiquetee = df_etiquetee.sort_values(by='CONS_NO').reset_index(drop=True)\ndf_validation = df_validation.sort_values(by='CONS_NO').reset_index(drop=True)\n\n# Comparer les étiquettes 'FLAG' dans les deux DataFrames\ny_true = df_validation['FLAG']\ny_pred = df_etiquetee['FLAG']\n\n# Calculer les métriques de performance\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, zero_division=0)\nrecall = recall_score(y_true, y_pred, zero_division=0)\nf1 = f1_score(y_true, y_pred, zero_division=0)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(f\"Precision: {precision:.2f}\")\nprint(f\"Recall: {recall:.2f}\")\nprint(f\"F1 Score: {f1:.2f}\")\n\n# 1. Histogramme des Correspondances et Non-Correspondances\nmatch = y_true == y_pred\nmatch_counts = match.value_counts()\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x=match_counts.index, y=match_counts.values, palette='viridis')\nplt.title('Correspondances et Non-Correspondances des Étiquettes')\nplt.xlabel('Correspondance')\nplt.ylabel('Nombre')\nplt.xticks(ticks=[0, 1], labels=['Non-Correspondance', 'Correspondance'])\nplt.show()\n\n# 2. Matrice de Confusion\nconf_matrix = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title('Matrice de Confusion')\nplt.xlabel('Étiquettes Prédites')\nplt.ylabel('Étiquettes Réelles')\nplt.show()\n\n# 3. Courbe ROC et AUC\nfpr, tpr, _ = roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(10, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Taux de Faux Positifs')\nplt.ylabel('Taux de Vrais Positifs')\nplt.title('Courbe ROC')\nplt.legend(loc='lower right')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]}]}