{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8134280,"sourceType":"datasetVersion","datasetId":4808241}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport statsmodels.api as sm\nimport warnings\nwarnings.filterwarnings('ignore')\nimport datetime","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('S:\\Mes documents\\Bureau\\PFE MID\\Les articles\\ElectricityTheftDetection\\SmartGridFraudDetection-master\\SmartGridFraudDetection-master\\data\\preprocessedR90.csv', header=0, parse_dates=[0], index_col=0, squeeze=True) \n\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Client AVEC FRAUD\n# Transposer les données\ndf_transposed = df.set_index('CONS_NO').T\n\n# Sélectionner les données à tracer (par exemple, CONS_NO='4B75AC4F2D8434CFF62DB64D0BB43103')\nselected_data = df_transposed['4B75AC4F2D8434CFF62DB64D0BB43103']\n\n# Convertir les index en datetime si nécessaire\nselected_data.index = pd.to_datetime(selected_data.index)\n\n# Tracer les données\nplt.figure(figsize=(15, 8))\nplt.plot(selected_data.index, selected_data.values)\nplt.xlabel('Date')\nplt.ylabel('Consommation')\nplt.title('Tracé des données pour CONS_NO=\"4B75AC4F2D8434CFF62DB64D0BB43103\"')\nselected_data.info()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# staionnarité","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom statsmodels.tsa.stattools import adfuller\nfrom numpy import log\n\n# Vous pouvez appliquer une transformation logarithmique si nécessaire\n# Pour cela, assurez-vous que toutes les valeurs de selected_data sont positives.\n# selected_data_log = log(selected_data.values)\n\n# Exécution du test ADF\nresult = adfuller(selected_data.values)\n\n# Affichage des résultats\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Number of lags used: %d' % result[2])\nprint('Number of observations used: %d' % result[3])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t%s: %.3f' % (key, value))\n\n# Interprétation des résultats\nif result[1] < 0.05:\n    print('La série est probablement stationnaire (rejeter l\\'hypothèse nulle d\\'une unité racine).')\nelse:\n    print('La série est probablement non-stationnaire (ne pas rejeter l\\'hypothèse nulle).')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Comme P_Value < 0.05 donc on rejet H0 ==> La série est stationnaire ","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.stattools import kpss\n\n# Assurez-vous que l'index de selected_data est de type datetime\n# Si ce n'est pas le cas, convertissez-le comme suit:\n# selected_data.index = pd.to_datetime(selected_data.index)\n\n# Exécution du test KPSS\nstatistic, p_value, n_lags, critical_values = kpss(selected_data, regression='c')\n\n# Affichage des résultats\nprint(f'Statistique de test: {statistic}')\nprint(f'P-value: {p_value}')\nprint(f'Nombre de retards utilisés: {n_lags}')\nprint('Valeurs critiques:')\nfor key, value in critical_values.items():\n    print(f'  {key} : {value}')\n\n# Interprétation de la sortie\nif p_value < 0.05:\n    print('La série est probablement non-stationnaire (rejeter H0).')\nelse:\n    print('La série est probablement stationnaire (ne pas rejeter H0).')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"P_Value > 0.05 ===> Stationnaire ","metadata":{}},{"cell_type":"markdown","source":"# Time Series Decomposition","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport matplotlib.pyplot as plt\n\n# Si selected_data est une série pandas, assurez-vous que l'index est un DatetimeIndex\nselected_data.index = pd.date_range(start='2014-01-01', periods=len(selected_data), freq='D')\n\n# Vérifiez que la fréquence est définie\nselected_data = selected_data.asfreq('D')  # Assurez-vous que c'est la bonne fréquence pour vos données\n\n# Spécifier une période si vous connaissez la saisonnalité typique de vos données\n# Par exemple, si vous savez que la saisonnalité est annuelle et que les données sont quotidiennes:\nperiod = 365\n\n# Appliquer la décomposition additive\ndecomposition = seasonal_decompose(selected_data, model='additive', period=period)\n\n# Tracer la décomposition\nfig = decomposition.plot()\nfig.set_size_inches(15, 8)\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Composante de tendance (Trend)\nLa tendance est relativement stable au début, légèrement descendante jusqu'à début 2015.\nDe début 2015 à mi-2016, la tendance diminue progressivement, ce qui pourrait indiquer une baisse globale de la consommation ou un changement dans les conditions sous-jacentes (techniques, économiques, comportementales).\nÀ partir de mi-2016, la tendance augmente, suggérant une récupération ou une augmentation de la consommation, peut-être due à une croissance de l'activité dans la zone ou à des changements dans les usages ou équipements énergétiques.\n\n2. Composante saisonnière (Seasonal)\nLa saisonnalité montre des fluctuations claires et répétitives tout au long de la série. Cela peut indiquer des variations saisonnières typiques en fonction des conditions météorologiques, des habitudes de consommation (comme le chauffage en hiver ou la climatisation en été), ou d'autres facteurs cycliques.\nL'amplitude de la saisonnalité reste assez constante tout au long de la période, ce qui indique que les motifs saisonniers ne changent pas significativement d'année en année.\n\n3. Résidus (Residual)\nLes résidus sont relativement stables autour de zéro, ce qui suggère que la décomposition a réussi à capturer la majeure partie de l'information de la série dans les composantes de tendance et saisonnière.\nCependant, on note quelques pics et creux notables à différents points, en particulier une augmentation des résidus à partir de 2016. Ces variations résiduelles peuvent indiquer des événements ou des anomalies non capturés par les composantes saisonnières ou de tendance, tels que des erreurs de mesure, des changements dans la consommation non liés à la saisonnalité, ou des événements exceptionnels.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\n# Remplacer les valeurs zéro ou négatives par une petite valeur positive (e.g., un petit pourcentage de la moyenne des valeurs non-nulles)\nmin_positive = selected_data[selected_data > 0].min()\nselected_data_M = selected_data.replace(0, min_positive * 0.1)\nselected_data_M = selected_data.where(selected_data > 0, min_positive * 0.1)\n\n# Appliquer la décomposition multiplicative\ndecomposition = sm.tsa.seasonal_decompose(selected_data_M, model='multiplicative')\n\n# Tracer la décomposition\nfig = decomposition.plot()\nfig.set_figwidth(15)\nfig.set_figheight(8)\nfig.suptitle('Decomposition of Multiplicative Time Series')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Tendance (Trend)\nLa tendance montre les variations à long terme de la consommation d'électricité sans tenir compte des fluctuations saisonnières ou des irrégularités. Dans mon graphique :\nDe début 2014 à mi-2015, on observe une tendance globalement stable avec une légère baisse vers le début de 2015.\nDe mi-2015 à début 2016, la tendance chute de manière plus significative, indiquant une réduction notable de la consommation.\nIl y a une augmentation marquée vers mi-2016, suivie d'une chute tout aussi significative. Ces changements brusques pourraient être dus à des événements exceptionnels ou des changements dans les habitudes de consommation.\n\n2. Saisonnalité (Seasonal)\nLa saisonnalité montre des motifs ou des cycles qui se répètent à intervalles réguliers, comme les saisons ou les jours de la semaine. Dans ce cas :\nLa saisonnalité est très régulière et montre des pics et des creux qui se répètent avec une périodicité constante à travers les années. Cette régularité pourrait indiquer des comportements prévisibles dans la consommation, possiblement liés aux cycles de vie quotidienne ou saisonnière des consommateurs.\n\n3. Résidus (Residual)\nLes résidus représentent la composante de la série temporelle qui n'est pas expliquée par la tendance ou la saisonnalité. Il s'agit essentiellement du bruit.\nLes résidus semblent relativement stables et dispersés autour de zéro sans schéma apparent, ce qui suggère que la plupart des variations de la consommation sont bien expliquées par la tendance et la saisonnalité.\nCependant, quelques résidus montrent des valeurs extrêmes (surtout vers 2016). Ces points extrêmes pourraient indiquer des anomalies ou des événements non capturés par le modèle de décomposition.","metadata":{}},{"cell_type":"raw","source":"Analyse de la Tendance\n\nMultiplicative: La tendance montre des pics soudains, notamment vers la fin de la période observée. Ces pics peuvent indiquer des périodes où la consommation a été artificiellement augmentée, ce qui est typique dans les cas de fraude, comme le détournement de l'électricité ou la manipulation de compteurs.\nAdditive: La tendance est plus lisse mais montre une augmentation progressive vers la fin, ce qui peut refléter un changement dans les habitudes de consommation ou peut-être une escalade dans les activités frauduleuses.\nAnalyse de la Saisonnalité\nMultiplicative: Les motifs saisonniers sont très réguliers mais montrent une amplitude croissante avec le temps, ce qui pourrait indiquer que la fraude est proportionnelle à la consommation. Cela est souvent le cas si le fraudeur ajuste son comportement en fonction des périodes de forte demande pour maximiser le bénéfice de la fraude.\nAdditive: La saisonnalité, bien qu'irrégulière, reste dans une bande relativement stable, suggérant que les manipulations ne sont pas directement liées aux variations saisonnières normales.\n\n\n\nAnalyse des Résidus\n\nLes résidus, particulièrement dans la décomposition multiplicative, montrent des écarts significatifs et des points aberrants autour des périodes où la tendance augmente brusquement. Ces résidus peuvent indiquer des anomalies spécifiques qui ne sont pas expliquées par des variations saisonnières ou des tendances naturelles, renforçant les suspicions de comportements frauduleux.\n\n\n\nRecommandations pour le Projet\n\nInvestigation Approfondie: Examiner les périodes correspondant aux pics anormaux et aux résidus élevés pour rechercher des preuves de fraude, comme des enregistrements de compteurs anormaux ou des correspondances avec des périodes de tarification élevée.\nAmélioration des Modèles de DétectionUtiliser ces patterns identifiés pour améliorer les algorithmes de détection de fraude. En intégrant les caractéristiques de la tendance et de la saisonnalité dans vos modèles, vous pouvez augmenter la précision de la détection en temps réel.\nRapport et Communication: Préparer un rapport détaillé pour les parties prenantes, incluant les services de régulation et de contrôle, en soulignant les périodes suspectes et en recommandant des mesures spécifiques pour la vérification et l'audit.","metadata":{}},{"cell_type":"markdown","source":"# ACF PACF ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\n# Supposons que 'selected_data' est votre série temporelle\n# Assurez-vous que l'index est de type datetime si ce n'est pas déjà le cas\nselected_data.index = pd.to_datetime(selected_data.index)\n\n# Tracer l'Autocorrélation (ACF)\nplt.figure(figsize=(12, 6))\nplot_acf(selected_data, alpha=0.05, lags=40)  # Vous pouvez ajuster les lags en fonction de votre série\nplt.title('Autocorrelation Function (ACF)')\nplt.show()\n\n# Tracer l'Autocorrélation Partielle (PACF)\nplt.figure(figsize=(12, 6))\nplot_pacf(selected_data, alpha=0.05, lags=40, method='ywm')  # 'ywm' est une méthode de calcul pour PACF\nplt.title('Partial Autocorrelation Function (PACF)')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Supposons que selected_data est votre série temporelle.\n# Assurez-vous que selected_data est un objet pandas Series avec un DateTimeIndex.\n\n# Différenciation Simple\ndiff_simple = selected_data.diff().dropna()\n\n\n# Afficher les séries différenciées\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 6))\nplt.subplot(211)\nplt.plot(diff_simple, label='Différenciation Simple')\nplt.title('Différenciation Simple')\nplt.legend()\n\n\nplt.tight_layout()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Stationnarité","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom statsmodels.tsa.stattools import adfuller\nfrom numpy import log\n\n# Vous pouvez appliquer une transformation logarithmique si nécessaire\n# Pour cela, assurez-vous que toutes les valeurs de selected_data sont positives.\n# selected_data_log = log(selected_data.values)\n\n# Exécution du test ADF\nresult = adfuller(diff_simple.values)\n\n# Affichage des résultats\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Number of lags used: %d' % result[2])\nprint('Number of observations used: %d' % result[3])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t%s: %.3f' % (key, value))\n\n# Interprétation des résultats\nif result[1] < 0.05:\n    print('La série est probablement stationnaire (rejeter l\\'hypothèse nulle d\\'une unité racine).')\nelse:\n    print('La série est probablement non-stationnaire (ne pas rejeter l\\'hypothèse nulle).')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\n# Supposons que selected_data est votre série temporelle.\n# Assurez-vous que selected_data est un objet pandas Series avec un DateTimeIndex.\n# Afficher les séries différenciées\nplt.figure(figsize=(12, 8))\n\n# ACF de la série différenciée\nplt.subplot(312)\nplot_acf(diff_simple, ax=plt.gca(), lags=40)\nplt.title('ACF de la Différenciation Simple')\n\n# PACF de la série différenciée\nplt.subplot(313)\nplot_pacf(diff_simple, ax=plt.gca(), lags=40)\nplt.title('PACF de la Différenciation Simple')\n\nplt.tight_layout()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Determine ARIMA models parameters p, q","metadata":{}},{"cell_type":"code","source":"import itertools\nfrom statsmodels.tsa.arima.model import ARIMA\n\n# Define range of p, d, q values\np_range = range(0, 5)  # Adjust based on the complexity of your data\nd_range = range(0, 5)\nq_range = range(0, 5)\n\n# Generate all possible combinations of p, d, q\npdq = list(itertools.product(p_range, d_range, q_range))\n\n# Grid search\nbest_aic = float(\"inf\")\nbest_pdq = None\nfor params in pdq:\n    try:\n        model = ARIMA(selected_data, order=params)\n        result = model.fit()\n        if result.aic < best_aic:\n            best_aic = result.aic\n            best_pdq = params\n    except:\n        continue\n\nprint(\"Best (p, d, q) parameters:\", best_pdq)\nprint(\"Best AIC:\", best_aic)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pmdarima as pm\n\n# Ajustement automatique du modèle ARIMA\nmodel = pm.auto_arima(selected_data)\n\n# Affichage du résumé du modèle\nprint(model.summary())\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pmdarima as pm\n\nmodel = pm.auto_arima(selected_data, seasonal=True, m=30)\nprint(model.summary())\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom math import sqrt\n# Create and fit the ARIMA model\n\nmodel = ARIMA(selected_data, order=(4, 0, 4))\n\nmodel_fit = model.fit()\n\n# Make predictions\nstart_index = 0\nend_index = len(selected_data) - 1\npredictions = model_fit.predict(start=start_index, end=end_index)\n\n# Calculate metrics\nmae = mean_absolute_error(selected_data, predictions)\nmse = mean_squared_error(selected_data, predictions)\nrmse = sqrt(mse)\nr2 = r2_score(selected_data, predictions)\n\n# Print metrics\nprint(f'Mean Absolute Error: {mae}')\nprint(f'Mean Squared Error: {mse}')\nprint(f'Root Mean Squared Error: {rmse}')\nprint(f'R-squared: {r2}')\n\n# Plot the predictions alongside the actual values\nplt.figure(figsize=(10,6))\nplt.plot(selected_data, label='Actual')\nplt.plot(predictions, label='Predicted')\nplt.legend(loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom math import sqrt\n# Create and fit the ARIMA model\nmodel = ARIMA(selected_data, order=(3, 0, 1))\n\n\nmodel_fit = model.fit()\n\n# Make predictions\nstart_index = 0\nend_index = len(selected_data) - 1\npredictions = model_fit.predict(start=start_index, end=end_index)\n\n# Calculate metrics\nmae = mean_absolute_error(selected_data, predictions)\nmse = mean_squared_error(selected_data, predictions)\nrmse = sqrt(mse)\nr2 = r2_score(selected_data, predictions)\n\n# Print metrics\nprint(f'Mean Absolute Error: {mae}')\nprint(f'Mean Squared Error: {mse}')\nprint(f'Root Mean Squared Error: {rmse}')\nprint(f'R-squared: {r2}')\n\n# Plot the predictions alongside the actual values\nplt.figure(figsize=(10,6))\nplt.plot(selected_data, label='Actual')\nplt.plot(predictions, label='Predicted')\nplt.legend(loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom math import sqrt\n# Create and fit the ARIMA model\nmodel = ARIMA(selected_data, order=(3, 1, 1))\n\n\nmodel_fit = model.fit()\n\n# Make predictions\nstart_index = 0\nend_index = len(selected_data) - 1\npredictions = model_fit.predict(start=start_index, end=end_index)\n\n# Calculate metrics\nmae = mean_absolute_error(selected_data, predictions)\nmse = mean_squared_error(selected_data, predictions)\nrmse = sqrt(mse)\nr2 = r2_score(selected_data, predictions)\n\n# Print metrics\nprint(f'Mean Absolute Error: {mae}')\nprint(f'Mean Squared Error: {mse}')\nprint(f'Root Mean Squared Error: {rmse}')\nprint(f'R-squared: {r2}')\n\n# Plot the predictions alongside the actual values\nplt.figure(figsize=(10,6))\nplt.plot(selected_data, label='Actual')\nplt.plot(predictions, label='Predicted')\nplt.legend(loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}